---
title: "The Anatomy of an Efficient Blackwell GEMM"
author: "Antonio Moral Villarín"
format: pdf
toc: true
number-sections: true
fontsize: 11pt
---

# Abstract {.unnumbered}

# Acknowledgements {.unnumbered}

# List of Figures and Tables {.unnumbered}
*To be auto-generated by Quarto.*

# Chapter 1 – Introduction
## Motivation and Context: The Need for Hardware–Software Co-Design
## Challenges in Efficient Compute for AI and Edge Applications
## Objectives and Scope of the Thesis
## Methodology Overview
## Structure of the Thesis

# Chapter 2 – Background and Related Work
## Evolution of GPU Architectures: From Volta to Blackwell
## Hardware–Software Co-Design: Principles and Applications
## General Matrix-Matrix Multiplication (GEMM) in AI Workloads
## Domain-Specific Languages (DSLs) for GPU Programming
## Relevant Publications and Tools (NVIDIA Research, Citadel, JAX Scaling Book, etc.)

# Chapter 3 – Architecture Comparison: Hopper vs Blackwell
## Overview of Hopper Architecture
## Overview of Blackwell Architecture
## Key Innovations in Blackwell
### Ultra Tensor Cores and New Precision Formats (FP8, FP4)
### Transformer Engine and FP4 Micro Scaling
### Multi-Die Chip Design and Interconnect (NVLink, NVSwitch)
### Memory System: HBM3e, L2 Cache, and Shared Memory
## Performance/Watt and Area Efficiency Considerations
## Summary of Architectural Differences

# Chapter 4 – Metrics for GPU Efficiency
## Performance per Watt
## Compute Throughput by Data Type
## Memory Bandwidth and Arithmetic Intensity
## Power, Thermal Design, and Silicon Area Constraints
## Efficiency Bottlenecks: From Memory Bound to Compute Bound

# Chapter 5 – Programming Models for Modern GPUs
## Introduction to GPU DSLs for Performance
## Triton
## ThunderKittens (TK)
## TileLang
## Cute and CUTLASS
## Gluon
## Pallas and the JAX ML Scaling Framework
## Summary: DSLs as Enablers of Architectural Efficiency

# Chapter 6 – Methodology and Experimental Setup
## Objectives of Benchmarking
## Hardware Platforms and Specifications
### Hopper H100
### Blackwell B200
## Software Tools and Libraries Used
## Microbenchmark Design: GEMM Kernel Implementations
## Measurement Techniques
### Throughput (FLOP/s)
### Power Consumption and Efficiency
### Memory Bandwidth
## Ensuring Fairness and Reproducibility

# Chapter 7 – Results and Discussion
## Performance Comparison Across Data Types
## Analysis of Performance per Watt
## Memory Bandwidth Observations
## Impact of TMA (Tensor Memory Accelerator)
## Roofline Analysis: Compute vs Memory Bound
## Real-World Relevance: Case Study on Transformer Inference/Training
## Discussion of Bottlenecks and Architectural Impact

# Chapter 8 – Conclusions and Future Work
## Summary of Findings
## Implications for Hardware–Software Co-Design
## Relevance to Edge Computing
## Future Work and Doctoral Research Directions

# References

# Appendices
## Appendix A: Experimental Scripts and Kernel Listings
## Appendix B: Extended Benchmark Results
## Appendix C: TMA and GEMM Intrinsics Documentation
